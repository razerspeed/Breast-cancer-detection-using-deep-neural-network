{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2189,
     "status": "ok",
     "timestamp": 1542543695321,
     "user": {
      "displayName": "Yinghan Xu",
      "photoUrl": "https://lh3.googleusercontent.com/-ZH_vkc0a6g0/AAAAAAAAAAI/AAAAAAAAAAc/x8TPjkqmxys/s64/photo.jpg",
      "userId": "13488364327507272606"
     },
     "user_tz": -480
    },
    "id": "qSbY3Amlqpkh",
    "outputId": "90795cb8-8374-4711-a036-e005c4c7b9d2"
   },
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "from __future__ import absolute_import\n",
    "import random\n",
    "import pprint\n",
    "import sys\n",
    "import time\n",
    "import numpy as np\n",
    "from optparse import OptionParser\n",
    "import pickle\n",
    "import math\n",
    "import cv2\n",
    "import copy\n",
    "from matplotlib import pyplot as plt\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "from sklearn.metrics import average_precision_score\n",
    "\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.optimizers import Adam, SGD, RMSprop\n",
    "from tensorflow.keras.layers import Flatten, Dense, Input, Conv2D, MaxPooling2D, Dropout ,Layer, InputSpec\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D, GlobalMaxPooling2D, TimeDistributed\n",
    "from tensorflow.keras.losses import categorical_crossentropy\n",
    "from tensorflow.keras.utils import get_file,get_source_inputs,Progbar\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras import initializers, regularizers\n",
    "from tensorflow.python.keras.utils import generic_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#create annotations from \n",
    "%run seg2bounding_box.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run utils.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "C66bqGuOq7w6"
   },
   "outputs": [],
   "source": [
    "base_path = 'etc'\n",
    "\n",
    "train_path =  'annotation.txt' # Training data (annotation file)\n",
    "\n",
    "num_rois = 4 # Number of RoIs to process at once.\n",
    "\n",
    "# Augmentation flag\n",
    "horizontal_flips = True # Augment with horizontal flips in training. \n",
    "vertical_flips = True   # Augment with vertical flips in training. \n",
    "rot_90 = True           # Augment with 90 degree rotations in training. \n",
    "\n",
    "output_weight_path = os.path.join(base_path, 'model/model_frcnn_vgg.hdf5')\n",
    "\n",
    "record_path = os.path.join(base_path, 'model/record.csv') # Record data (used to save the losses, classification accuracy and mean average precision)\n",
    "\n",
    "base_weight_path = os.path.join(base_path, 'model/vgg16_weights_tf_dim_ordering_tf_kernels.h5')\n",
    "\n",
    "config_output_filename = os.path.join(base_path, 'model_vgg_config.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "J3oAmbbEutH0"
   },
   "outputs": [],
   "source": [
    "# Create the config\n",
    "C = Config()\n",
    "\n",
    "C.use_horizontal_flips = horizontal_flips\n",
    "C.use_vertical_flips = vertical_flips\n",
    "C.rot_90 = rot_90\n",
    "\n",
    "C.record_path = record_path\n",
    "C.model_path = output_weight_path\n",
    "C.num_rois = num_rois\n",
    "\n",
    "C.base_net_weights = base_weight_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 36108,
     "status": "ok",
     "timestamp": 1542545119215,
     "user": {
      "displayName": "Yinghan Xu",
      "photoUrl": "https://lh3.googleusercontent.com/-ZH_vkc0a6g0/AAAAAAAAAAI/AAAAAAAAAAc/x8TPjkqmxys/s64/photo.jpg",
      "userId": "13488364327507272606"
     },
     "user_tz": -480
    },
    "id": "yiEaAmb-x-so",
    "outputId": "eb280e97-7692-470f-fbf2-e0f1cf29ef31"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing annotation files\n",
      "\r",
      "idx=1\r",
      "idx=2\r",
      "idx=3\r",
      "idx=4\r",
      "idx=5\r",
      "idx=6\r",
      "idx=7\r",
      "idx=8\r",
      "idx=9\r",
      "idx=10\r",
      "idx=11\r",
      "idx=12\r",
      "idx=13\r",
      "idx=14\n",
      "Spend 0.00 mins to load the data\n"
     ]
    }
   ],
   "source": [
    "#--------------------------------------------------------#\n",
    "# This step will spend some time to load the data        #\n",
    "#--------------------------------------------------------#\n",
    "st = time.time()\n",
    "train_imgs, classes_count, class_mapping = get_data(train_path)\n",
    "print()\n",
    "print('Spend %0.2f mins to load the data' % ((time.time()-st)/60) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 232
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1523,
     "status": "error",
     "timestamp": 1542596406207,
     "user": {
      "displayName": "Yinghan Xu",
      "photoUrl": "https://lh3.googleusercontent.com/-ZH_vkc0a6g0/AAAAAAAAAAI/AAAAAAAAAAc/x8TPjkqmxys/s64/photo.jpg",
      "userId": "13488364327507272606"
     },
     "user_tz": -480
    },
    "id": "x-nuSdC56GsK",
    "outputId": "7b7d16df-5aa4-4b7a-decf-b0b24eec0758"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training images per class:\n",
      "{'bg': 0, 'mitosis': 14}\n",
      "Num classes (including bg) = 2\n",
      "{'mitosis': 0, 'bg': 1}\n",
      "Config has been written to etc\\model_vgg_config.pickle, and can be loaded when testing to ensure correct results\n"
     ]
    }
   ],
   "source": [
    "if 'bg' not in classes_count:\n",
    "\tclasses_count['bg'] = 0\n",
    "\tclass_mapping['bg'] = len(class_mapping)\n",
    "# e.g.\n",
    "#    classes_count: {'Car': 2383, 'Mobile phone': 1108, 'Person': 3745, 'bg': 0}\n",
    "#    class_mapping: {'Person': 0, 'Car': 1, 'Mobile phone': 2, 'bg': 3}\n",
    "C.class_mapping = class_mapping\n",
    "\n",
    "print('Training images per class:')\n",
    "pprint.pprint(classes_count)\n",
    "print('Num classes (including bg) = {}'.format(len(classes_count)))\n",
    "print(class_mapping)\n",
    "\n",
    "# Save the configuration\n",
    "with open(config_output_filename, 'wb') as config_f:\n",
    "\tpickle.dump(C,config_f)\n",
    "\tprint('Config has been written to {}, and can be loaded when testing to ensure correct results'.format(config_output_filename))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 610,
     "status": "ok",
     "timestamp": 1542545124369,
     "user": {
      "displayName": "Yinghan Xu",
      "photoUrl": "https://lh3.googleusercontent.com/-ZH_vkc0a6g0/AAAAAAAAAAI/AAAAAAAAAAc/x8TPjkqmxys/s64/photo.jpg",
      "userId": "13488364327507272606"
     },
     "user_tz": -480
    },
    "id": "LFlq36Sx4F4O",
    "outputId": "e2576f93-290b-48ff-ed8c-fda147fc53df"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num train samples (images) 1\n"
     ]
    }
   ],
   "source": [
    "# Shuffle the images with seed\n",
    "random.seed(1)\n",
    "random.shuffle(train_imgs)\n",
    "\n",
    "print('Num train samples (images) {}'.format(len(train_imgs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GXIV1uXyBo3v"
   },
   "outputs": [],
   "source": [
    "# Get train data generator which generate X, Y, image_data\n",
    "data_gen_train = get_anchor_gt(train_imgs, C, get_img_output_length, mode='train')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "y_yM5jkKqM1G"
   },
   "source": [
    "#### Explore 'data_gen_train'\n",
    "\n",
    "data_gen_train is an **generator**, so we get the data by calling **next(data_gen_train)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nIDnio1UlRHi"
   },
   "outputs": [],
   "source": [
    "X, Y, image_data, debug_img, debug_num_pos = next(data_gen_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 848
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1611,
     "status": "ok",
     "timestamp": 1542544779625,
     "user": {
      "displayName": "Yinghan Xu",
      "photoUrl": "https://lh3.googleusercontent.com/-ZH_vkc0a6g0/AAAAAAAAAAI/AAAAAAAAAAc/x8TPjkqmxys/s64/photo.jpg",
      "userId": "13488364327507272606"
     },
     "user_tz": -480
    },
    "id": "dZXoJ2e3l2Ey",
    "outputId": "eb1a0f85-93f4-46cb-9046-77afd48b59b5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original image: height=1280 width=1536\n",
      "Resized image:  height=300 width=360 C.im_size=300\n",
      "Feature map size: height=18 width=22 C.rpn_stride=16\n",
      "(1, 300, 360, 3)\n",
      "2 includes 'y_rpn_cls' and 'y_rpn_regr'\n",
      "Shape of y_rpn_cls (1, 18, 22, 18)\n",
      "Shape of y_rpn_regr (1, 18, 22, 72)\n",
      "{'filepath': 'Unet-result.png', 'width': 1536, 'height': 1280, 'bboxes': [{'class': 'mitosis', 'x1': 27, 'x2': 47, 'y1': 463, 'y2': 485}, {'class': 'mitosis', 'x1': 246, 'x2': 250, 'y1': 743, 'y2': 747}, {'class': 'mitosis', 'x1': 246, 'x2': 247, 'y1': -153, 'y2': -151}, {'class': 'mitosis', 'x1': 272, 'x2': 285, 'y1': 91, 'y2': 104}, {'class': 'mitosis', 'x1': 280, 'x2': 285, 'y1': 1026, 'y2': 1036}, {'class': 'mitosis', 'x1': 484, 'x2': 509, 'y1': -103, 'y2': -74}, {'class': 'mitosis', 'x1': 556, 'x2': 573, 'y1': 863, 'y2': 881}, {'class': 'mitosis', 'x1': 571, 'x2': 576, 'y1': 767, 'y2': 768}, {'class': 'mitosis', 'x1': 577, 'x2': 578, 'y1': 767, 'y2': 768}, {'class': 'mitosis', 'x1': 666, 'x2': 673, 'y1': 1026, 'y2': 1033}, {'class': 'mitosis', 'x1': 798, 'x2': 805, 'y1': 1052, 'y2': 1059}, {'class': 'mitosis', 'x1': 1052, 'x2': 1068, 'y1': 1025, 'y2': 1041}, {'class': 'mitosis', 'x1': 1121, 'x2': 1144, 'y1': 176, 'y2': 207}, {'class': 'mitosis', 'x1': 1259, 'x2': 1262, 'y1': 923, 'y2': 926}]}\n",
      "Number of positive anchors for this image: 11\n",
      "(array([ 2,  2,  2,  2,  2,  3,  4,  4,  4,  9,  9,  9,  9, 10, 10, 11, 11,\n",
      "       11, 12, 12, 12, 13, 13, 13, 13, 13, 13, 13, 14, 14, 14, 14, 16],\n",
      "      dtype=int64), array([ 2,  2,  9, 15, 15, 10,  1,  1, 13,  2,  2,  6,  6,  2, 16,  4,  6,\n",
      "        6,  8, 16, 16,  2,  2,  7,  8,  8, 14, 14, 10, 10, 11, 18,  9],\n",
      "      dtype=int64), array([ 0,  9,  0,  0,  9,  5,  1, 10,  3,  0,  9,  0,  9,  1,  2,  3,  0,\n",
      "        9,  4,  0,  9,  0,  9,  3,  0,  9,  0,  9,  0,  9,  3,  0,  2],\n",
      "      dtype=int64))\n",
      "(array([ 2,  2,  2,  2,  2,  2,  2,  2,  4,  4,  4,  4,  9,  9,  9,  9,  9,\n",
      "        9,  9,  9, 11, 11, 11, 11, 12, 12, 12, 12, 13, 13, 13, 13, 13, 13,\n",
      "       13, 13, 13, 13, 13, 13, 14, 14, 14, 14], dtype=int64), array([ 2,  2,  2,  2, 15, 15, 15, 15,  1,  1,  1,  1,  2,  2,  2,  2,  6,\n",
      "        6,  6,  6,  6,  6,  6,  6, 16, 16, 16, 16,  2,  2,  2,  2,  8,  8,\n",
      "        8,  8, 14, 14, 14, 14, 10, 10, 10, 10], dtype=int64), array([0, 1, 2, 3, 0, 1, 2, 3, 4, 5, 6, 7, 0, 1, 2, 3, 0, 1, 2, 3, 0, 1,\n",
      "       2, 3, 0, 1, 2, 3, 0, 1, 2, 3, 0, 1, 2, 3, 0, 1, 2, 3, 0, 1, 2, 3],\n",
      "      dtype=int64))\n",
      "y_rpn_cls for possible pos anchor: [1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "y_rpn_regr for positive anchor: [  1.           1.           1.           1.           0.\n",
      "   0.           0.           0.           0.           0.\n",
      "   0.           0.           0.           0.           0.\n",
      "   0.           0.           0.           0.           0.\n",
      "   0.           0.           0.           0.           0.\n",
      "   0.           0.           0.           0.           0.\n",
      "   0.           0.           0.           0.           0.\n",
      "   0.           1.57958984  -1.07177734 -12.17906666 -12.17906666\n",
      "   0.           0.           0.           0.           0.\n",
      "   0.           0.           0.           0.           0.\n",
      "   0.           0.           0.           0.           0.\n",
      "   0.           0.           0.           0.           0.\n",
      "   0.           0.           0.           0.           0.\n",
      "   0.           0.           0.           0.           0.\n",
      "   0.           0.        ]\n",
      "Center position of positive anchor:  (32, 32)\n",
      "Center position of positive anchor:  (240, 32)\n",
      "Center position of positive anchor:  (16, 64)\n",
      "Center position of positive anchor:  (32, 144)\n",
      "Center position of positive anchor:  (96, 144)\n",
      "Center position of positive anchor:  (96, 176)\n",
      "Center position of positive anchor:  (256, 192)\n",
      "Center position of positive anchor:  (32, 208)\n",
      "Center position of positive anchor:  (128, 208)\n",
      "Center position of positive anchor:  (224, 208)\n",
      "Center position of positive anchor:  (160, 224)\n",
      "Green bboxes is ground-truth bbox. Others are positive anchors\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print('Original image: height=%d width=%d'%(image_data['height'], image_data['width']))\n",
    "print('Resized image:  height=%d width=%d C.im_size=%d'%(X.shape[1], X.shape[2], C.im_size))\n",
    "print('Feature map size: height=%d width=%d C.rpn_stride=%d'%(Y[0].shape[1], Y[0].shape[2], C.rpn_stride))\n",
    "print(X.shape)\n",
    "print(str(len(Y))+\" includes 'y_rpn_cls' and 'y_rpn_regr'\")\n",
    "print('Shape of y_rpn_cls {}'.format(Y[0].shape))\n",
    "print('Shape of y_rpn_regr {}'.format(Y[1].shape))\n",
    "print(image_data)\n",
    "\n",
    "print('Number of positive anchors for this image: %d' % (debug_num_pos))\n",
    "if debug_num_pos==0:\n",
    "    gt_x1, gt_x2 = image_data['bboxes'][0]['x1']*(X.shape[2]/image_data['height']), image_data['bboxes'][0]['x2']*(X.shape[2]/image_data['height'])\n",
    "    gt_y1, gt_y2 = image_data['bboxes'][0]['y1']*(X.shape[1]/image_data['width']), image_data['bboxes'][0]['y2']*(X.shape[1]/image_data['width'])\n",
    "    gt_x1, gt_y1, gt_x2, gt_y2 = int(gt_x1), int(gt_y1), int(gt_x2), int(gt_y2)\n",
    "\n",
    "    img = debug_img.copy()\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    color = (0, 255, 0)\n",
    "    cv2.putText(img, 'gt bbox', (gt_x1, gt_y1-5), cv2.FONT_HERSHEY_DUPLEX, 0.7, color, 1)\n",
    "    cv2.rectangle(img, (gt_x1, gt_y1), (gt_x2, gt_y2), color, 2)\n",
    "    cv2.circle(img, (int((gt_x1+gt_x2)/2), int((gt_y1+gt_y2)/2)), 3, color, -1)\n",
    "\n",
    "    plt.grid()\n",
    "    plt.imshow(img)\n",
    "    plt.show()\n",
    "else:\n",
    "    cls = Y[0][0]\n",
    "    pos_cls = np.where(cls==1)\n",
    "    print(pos_cls)\n",
    "    regr = Y[1][0]\n",
    "    pos_regr = np.where(regr==1)\n",
    "    print(pos_regr)\n",
    "    print('y_rpn_cls for possible pos anchor: {}'.format(cls[pos_cls[0][0],pos_cls[1][0],:]))\n",
    "    print('y_rpn_regr for positive anchor: {}'.format(regr[pos_regr[0][0],pos_regr[1][0],:]))\n",
    "\n",
    "    gt_x1, gt_x2 = image_data['bboxes'][0]['x1']*(X.shape[2]/image_data['width']), image_data['bboxes'][0]['x2']*(X.shape[2]/image_data['width'])\n",
    "    gt_y1, gt_y2 = image_data['bboxes'][0]['y1']*(X.shape[1]/image_data['height']), image_data['bboxes'][0]['y2']*(X.shape[1]/image_data['height'])\n",
    "    gt_x1, gt_y1, gt_x2, gt_y2 = int(gt_x1), int(gt_y1), int(gt_x2), int(gt_y2)\n",
    "\n",
    "    img = debug_img.copy()\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    color = (0, 255, 0)\n",
    "    #   cv2.putText(img, 'gt bbox', (gt_x1, gt_y1-5), cv2.FONT_HERSHEY_DUPLEX, 0.7, color, 1)\n",
    "    cv2.rectangle(img, (gt_x1, gt_y1), (gt_x2, gt_y2), color, 2)\n",
    "    cv2.circle(img, (int((gt_x1+gt_x2)/2), int((gt_y1+gt_y2)/2)), 3, color, -1)\n",
    "\n",
    "    # Add text\n",
    "    textLabel = 'gt bbox'\n",
    "    (retval,baseLine) = cv2.getTextSize(textLabel,cv2.FONT_HERSHEY_COMPLEX,0.5,1)\n",
    "    textOrg = (gt_x1, gt_y1+5)\n",
    "    cv2.rectangle(img, (textOrg[0] - 5, textOrg[1]+baseLine - 5), (textOrg[0]+retval[0] + 5, textOrg[1]-retval[1] - 5), (0, 0, 0), 2)\n",
    "    cv2.rectangle(img, (textOrg[0] - 5,textOrg[1]+baseLine - 5), (textOrg[0]+retval[0] + 5, textOrg[1]-retval[1] - 5), (255, 255, 255), -1)\n",
    "    cv2.putText(img, textLabel, textOrg, cv2.FONT_HERSHEY_DUPLEX, 0.5, (0, 0, 0), 1)\n",
    "\n",
    "    # Draw positive anchors according to the y_rpn_regr\n",
    "    for i in range(debug_num_pos):\n",
    "\n",
    "        color = (100+i*(155/4), 0, 100+i*(155/4))\n",
    "\n",
    "        idx = pos_regr[2][i*4]/4\n",
    "        anchor_size = C.anchor_box_scales[int(idx/3)]\n",
    "        anchor_ratio = C.anchor_box_ratios[2-int((idx+1)%3)]\n",
    "\n",
    "        center = (pos_regr[1][i*4]*C.rpn_stride, pos_regr[0][i*4]*C.rpn_stride)\n",
    "        print('Center position of positive anchor: ', center)\n",
    "        cv2.circle(img, center, 3, color, -1)\n",
    "        anc_w, anc_h = anchor_size*anchor_ratio[0], anchor_size*anchor_ratio[1]\n",
    "        cv2.rectangle(img, (center[0]-int(anc_w/2), center[1]-int(anc_h/2)), (center[0]+int(anc_w/2), center[1]+int(anc_h/2)), color, 2)\n",
    "#         cv2.putText(img, 'pos anchor bbox '+str(i+1), (center[0]-int(anc_w/2), center[1]-int(anc_h/2)-5), cv2.FONT_HERSHEY_DUPLEX, 0.5, color, 1)\n",
    "\n",
    "print('Green bboxes is ground-truth bbox. Others are positive anchors')\n",
    "plt.figure(figsize=(8,8))\n",
    "plt.grid()\n",
    "plt.imshow(img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "i4XSyIoubCMY"
   },
   "source": [
    "#### Build the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jODipXFDnDJ0"
   },
   "outputs": [],
   "source": [
    "input_shape_img = (None, None, 3)\n",
    "\n",
    "img_input = Input(shape=input_shape_img)\n",
    "roi_input = Input(shape=(None, 4))\n",
    "\n",
    "# define the base network (VGG here, can be Resnet50, Inception, etc)\n",
    "shared_layers = nn_base(img_input, trainable=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the RPN, built on the base layers\n",
    "num_anchors = len(C.anchor_box_scales) * len(C.anchor_box_ratios) # 9\n",
    "rpn = rpn_layer(shared_layers, num_anchors)\n",
    " \n",
    "classifier = classifier_layer(shared_layers, roi_input, C.num_rois, nb_classes=len(classes_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 10162,
     "status": "ok",
     "timestamp": 1542545147976,
     "user": {
      "displayName": "Yinghan Xu",
      "photoUrl": "https://lh3.googleusercontent.com/-ZH_vkc0a6g0/AAAAAAAAAAI/AAAAAAAAAAc/x8TPjkqmxys/s64/photo.jpg",
      "userId": "13488364327507272606"
     },
     "user_tz": -480
    },
    "id": "udTeQMVhfSzw",
    "outputId": "11c3bda4-96e2-4658-ab6f-e5bf38519178"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the first time of your training\n",
      "loading weights from etc\\model/vgg16_weights_tf_dim_ordering_tf_kernels.h5\n",
      "Could not load pretrained model weights. Weights can be found in the keras application folder             https://github.com/fchollet/keras/tree/master/keras/applications\n"
     ]
    }
   ],
   "source": [
    "model_rpn = Model(img_input, rpn[:2])\n",
    "model_classifier = Model([img_input, roi_input], classifier)\n",
    "\n",
    "# this is a model that holds both the RPN and the classifier, used to load/save weights for the models\n",
    "model_all = Model([img_input, roi_input], rpn[:2] + classifier)\n",
    "\n",
    "# Because the google colab can only run the session several hours one time (then you need to connect again), \n",
    "# we need to save the model and load the model to continue training\n",
    "if not os.path.isfile(C.model_path):\n",
    "    #If this is the begin of the training, load the pre-traind base network such as vgg-16\n",
    "    try:\n",
    "        print('This is the first time of your training')\n",
    "        print('loading weights from {}'.format(C.base_net_weights))\n",
    "        model_rpn.load_weights(C.base_net_weights, by_name=True)\n",
    "        model_classifier.load_weights(C.base_net_weights, by_name=True)\n",
    "    except:\n",
    "        print('Could not load pretrained model weights. Weights can be found in the keras application folder \\\n",
    "            https://github.com/fchollet/keras/tree/master/keras/applications')\n",
    "    \n",
    "    # Create the record.csv file to record losses, acc and mAP\n",
    "    record_df = pd.DataFrame(columns=['mean_overlapping_bboxes', 'class_acc', 'loss_rpn_cls', 'loss_rpn_regr', 'loss_class_cls', 'loss_class_regr', 'curr_loss', 'elapsed_time', 'mAP'])\n",
    "else:\n",
    "    # If this is a continued training, load the trained model from before\n",
    "    print('Continue training based on previous trained model')\n",
    "    print('Loading weights from {}'.format(C.model_path))\n",
    "    model_rpn.load_weights(C.model_path, by_name=True)\n",
    "    model_classifier.load_weights(C.model_path, by_name=True)\n",
    "    \n",
    "    # Load the records\n",
    "    record_df = pd.read_csv(record_path)\n",
    "\n",
    "    r_mean_overlapping_bboxes = record_df['mean_overlapping_bboxes']\n",
    "    r_class_acc = record_df['class_acc']\n",
    "    r_loss_rpn_cls = record_df['loss_rpn_cls']\n",
    "    r_loss_rpn_regr = record_df['loss_rpn_regr']\n",
    "    r_loss_class_cls = record_df['loss_class_cls']\n",
    "    r_loss_class_regr = record_df['loss_class_regr']\n",
    "    r_curr_loss = record_df['curr_loss']\n",
    "    r_elapsed_time = record_df['elapsed_time']\n",
    "    r_mAP = record_df['mAP']\n",
    "\n",
    "    print('Already train %dK batches'% (len(record_df)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-ULrg0V1soIR"
   },
   "outputs": [],
   "source": [
    "optimizer = Adam(lr=1e-5)\n",
    "optimizer_classifier = Adam(lr=1e-5)\n",
    "model_rpn.compile(optimizer=optimizer, loss=[rpn_loss_cls(num_anchors), rpn_loss_regr(num_anchors)])\n",
    "model_classifier.compile(optimizer=optimizer_classifier, loss=[class_loss_cls, class_loss_regr(len(classes_count)-1)], metrics={'dense_class_{}'.format(len(classes_count)): 'accuracy'})\n",
    "model_all.compile(optimizer='sgd', loss='mae')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Qz2BYzL6sqfu"
   },
   "outputs": [],
   "source": [
    "# Training setting\n",
    "total_epochs = len(record_df)\n",
    "r_epochs = len(record_df)\n",
    "\n",
    "epoch_length = 5 #1000\n",
    "num_epochs = 1 #40\n",
    "iter_num = 0\n",
    "\n",
    "total_epochs += num_epochs\n",
    "\n",
    "losses = np.zeros((epoch_length, 5))\n",
    "rpn_accuracy_rpn_monitor = []\n",
    "rpn_accuracy_for_epoch = []\n",
    "\n",
    "if len(record_df)==0:\n",
    "    best_loss = np.Inf\n",
    "else:\n",
    "    best_loss = np.min(r_curr_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 4916
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1332624,
     "status": "ok",
     "timestamp": 1542188908991,
     "user": {
      "displayName": "Yinghan Xu",
      "photoUrl": "https://lh3.googleusercontent.com/-ZH_vkc0a6g0/AAAAAAAAAAI/AAAAAAAAAAc/x8TPjkqmxys/s64/photo.jpg",
      "userId": "13488364327507272606"
     },
     "user_tz": -480
    },
    "id": "dRXtd5W30DRN",
    "outputId": "438803d3-01c9-4818-859b-9a54e0243f93"
   },
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "for epoch_num in range(num_epochs):\n",
    "\n",
    "    progbar = generic_utils.Progbar(epoch_length)\n",
    "    print('Epoch {}/{}'.format(r_epochs + 1, total_epochs))\n",
    "    \n",
    "    r_epochs += 1\n",
    "\n",
    "    while True:\n",
    "        try:\n",
    "\n",
    "            if len(rpn_accuracy_rpn_monitor) == epoch_length and C.verbose:\n",
    "                mean_overlapping_bboxes = float(sum(rpn_accuracy_rpn_monitor))/len(rpn_accuracy_rpn_monitor)\n",
    "                rpn_accuracy_rpn_monitor = []\n",
    "#                 print('Average number of overlapping bounding boxes from RPN = {} for {} previous iterations'.format(mean_overlapping_bboxes, epoch_length))\n",
    "                if mean_overlapping_bboxes == 0:\n",
    "                    print('RPN is not producing bounding boxes that overlap the ground truth boxes. Check RPN settings or keep training.')\n",
    "\n",
    "            # Generate X (x_img) and label Y ([y_rpn_cls, y_rpn_regr])\n",
    "            X, Y, img_data, debug_img, debug_num_pos = next(data_gen_train)\n",
    "\n",
    "            # Train rpn model and get loss value [_, loss_rpn_cls, loss_rpn_regr]\n",
    "            loss_rpn = model_rpn.train_on_batch(X, Y)\n",
    "\n",
    "            # Get predicted rpn from rpn model [rpn_cls, rpn_regr]\n",
    "            P_rpn = model_rpn.predict_on_batch(X)\n",
    "\n",
    "            # R: bboxes (shape=(300,4))\n",
    "            # Convert rpn layer to roi bboxes\n",
    "            R = rpn_to_roi(P_rpn[0], P_rpn[1], C, K.common.image_dim_ordering(), use_regr=True, overlap_thresh=0.7, max_boxes=300)\n",
    "            \n",
    "            # note: calc_iou converts from (x1,y1,x2,y2) to (x,y,w,h) format\n",
    "            # X2: bboxes that iou > C.classifier_min_overlap for all gt bboxes in 300 non_max_suppression bboxes\n",
    "            # Y1: one hot code for bboxes from above => x_roi (X)\n",
    "            # Y2: corresponding labels and corresponding gt bboxes\n",
    "            X2, Y1, Y2, IouS = calc_iou(R, img_data, C, class_mapping)\n",
    "\n",
    "            # If X2 is None means there are no matching bboxes\n",
    "            if X2 is None:\n",
    "                rpn_accuracy_rpn_monitor.append(0)\n",
    "                rpn_accuracy_for_epoch.append(0)\n",
    "                continue\n",
    "            \n",
    "            # Find out the positive anchors and negative anchors\n",
    "            neg_samples = np.where(Y1[0, :, -1] == 1)\n",
    "            pos_samples = np.where(Y1[0, :, -1] == 0)\n",
    "\n",
    "            if len(neg_samples) > 0:\n",
    "                neg_samples = neg_samples[0]\n",
    "            else:\n",
    "                neg_samples = []\n",
    "\n",
    "            if len(pos_samples) > 0:\n",
    "                pos_samples = pos_samples[0]\n",
    "            else:\n",
    "                pos_samples = []\n",
    "\n",
    "            rpn_accuracy_rpn_monitor.append(len(pos_samples))\n",
    "            rpn_accuracy_for_epoch.append((len(pos_samples)))\n",
    "\n",
    "            if C.num_rois > 1:\n",
    "                # If number of positive anchors is larger than 4//2 = 2, randomly choose 2 pos samples\n",
    "                if len(pos_samples) < C.num_rois//2:\n",
    "                    selected_pos_samples = pos_samples.tolist()\n",
    "                else:\n",
    "                    selected_pos_samples = np.random.choice(pos_samples, C.num_rois//2, replace=False).tolist()\n",
    "                \n",
    "                # Randomly choose (num_rois - num_pos) neg samples\n",
    "                try:\n",
    "                    selected_neg_samples = np.random.choice(neg_samples, C.num_rois - len(selected_pos_samples), replace=False).tolist()\n",
    "                except:\n",
    "                    selected_neg_samples = np.random.choice(neg_samples, C.num_rois - len(selected_pos_samples), replace=True).tolist()\n",
    "                \n",
    "                # Save all the pos and neg samples in sel_samples\n",
    "                sel_samples = selected_pos_samples + selected_neg_samples\n",
    "            else:\n",
    "                # in the extreme case where num_rois = 1, we pick a random pos or neg sample\n",
    "                selected_pos_samples = pos_samples.tolist()\n",
    "                selected_neg_samples = neg_samples.tolist()\n",
    "                if np.random.randint(0, 2):\n",
    "                    sel_samples = random.choice(neg_samples)\n",
    "                else:\n",
    "                    sel_samples = random.choice(pos_samples)\n",
    "\n",
    "            # training_data: [X, X2[:, sel_samples, :]]\n",
    "            # labels: [Y1[:, sel_samples, :], Y2[:, sel_samples, :]]\n",
    "            #  X                     => img_data resized image\n",
    "            #  X2[:, sel_samples, :] => num_rois (4 in here) bboxes which contains selected neg and pos\n",
    "            #  Y1[:, sel_samples, :] => one hot encode for num_rois bboxes which contains selected neg and pos\n",
    "            #  Y2[:, sel_samples, :] => labels and gt bboxes for num_rois bboxes which contains selected neg and pos\n",
    "            loss_class = model_classifier.train_on_batch([X, X2[:, sel_samples, :]], [Y1[:, sel_samples, :], Y2[:, sel_samples, :]])\n",
    "\n",
    "            losses[iter_num, 0] = loss_rpn[1]\n",
    "            losses[iter_num, 1] = loss_rpn[2]\n",
    "\n",
    "            losses[iter_num, 2] = loss_class[1]\n",
    "            losses[iter_num, 3] = loss_class[2]\n",
    "            losses[iter_num, 4] = loss_class[3]\n",
    "\n",
    "            iter_num += 1\n",
    "\n",
    "            progbar.update(iter_num, [('rpn_cls', np.mean(losses[:iter_num, 0])), ('rpn_regr', np.mean(losses[:iter_num, 1])),\n",
    "                                      ('final_cls', np.mean(losses[:iter_num, 2])), ('final_regr', np.mean(losses[:iter_num, 3]))])\n",
    "\n",
    "            if iter_num == epoch_length:\n",
    "                loss_rpn_cls = np.mean(losses[:, 0])\n",
    "                loss_rpn_regr = np.mean(losses[:, 1])\n",
    "                loss_class_cls = np.mean(losses[:, 2])\n",
    "                loss_class_regr = np.mean(losses[:, 3])\n",
    "                class_acc = np.mean(losses[:, 4])\n",
    "\n",
    "                mean_overlapping_bboxes = float(sum(rpn_accuracy_for_epoch)) / len(rpn_accuracy_for_epoch)\n",
    "                rpn_accuracy_for_epoch = []\n",
    "\n",
    "                if C.verbose:\n",
    "                    print('Mean number of bounding boxes from RPN overlapping ground truth boxes: {}'.format(mean_overlapping_bboxes))\n",
    "                    print('Classifier accuracy for bounding boxes from RPN: {}'.format(class_acc))\n",
    "                    print('Loss RPN classifier: {}'.format(loss_rpn_cls))\n",
    "                    print('Loss RPN regression: {}'.format(loss_rpn_regr))\n",
    "                    print('Loss Detector classifier: {}'.format(loss_class_cls))\n",
    "                    print('Loss Detector regression: {}'.format(loss_class_regr))\n",
    "                    print('Total loss: {}'.format(loss_rpn_cls + loss_rpn_regr + loss_class_cls + loss_class_regr))\n",
    "                    print('Elapsed time: {}'.format(time.time() - start_time))\n",
    "                    elapsed_time = (time.time()-start_time)/60\n",
    "\n",
    "                curr_loss = loss_rpn_cls + loss_rpn_regr + loss_class_cls + loss_class_regr\n",
    "                iter_num = 0\n",
    "                start_time = time.time()\n",
    "\n",
    "                if curr_loss < best_loss:\n",
    "                    if C.verbose:\n",
    "                        print('Total loss decreased from {} to {}, saving weights'.format(best_loss,curr_loss))\n",
    "                    best_loss = curr_loss\n",
    "                    model_all.save_weights(C.model_path)\n",
    "\n",
    "                new_row = {'mean_overlapping_bboxes':round(mean_overlapping_bboxes, 3), \n",
    "                           'class_acc':round(class_acc, 3), \n",
    "                           'loss_rpn_cls':round(loss_rpn_cls, 3), \n",
    "                           'loss_rpn_regr':round(loss_rpn_regr, 3), \n",
    "                           'loss_class_cls':round(loss_class_cls, 3), \n",
    "                           'loss_class_regr':round(loss_class_regr, 3), \n",
    "                           'curr_loss':round(curr_loss, 3), \n",
    "                           'elapsed_time':round(elapsed_time, 3), \n",
    "                           'mAP': 0}\n",
    "\n",
    "                record_df = record_df.append(new_row, ignore_index=True)\n",
    "                record_df.to_csv(record_path, index=0)\n",
    "\n",
    "                break\n",
    "\n",
    "        except Exception as e:\n",
    "            print('Exception: {}'.format(e))\n",
    "            continue\n",
    "\n",
    "print('Training complete, exiting.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1316
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 4761,
     "status": "ok",
     "timestamp": 1542545625897,
     "user": {
      "displayName": "Yinghan Xu",
      "photoUrl": "https://lh3.googleusercontent.com/-ZH_vkc0a6g0/AAAAAAAAAAI/AAAAAAAAAAc/x8TPjkqmxys/s64/photo.jpg",
      "userId": "13488364327507272606"
     },
     "user_tz": -480
    },
    "id": "Kt-1Grs90oD3",
    "outputId": "bc9b57eb-e573-447f-a13e-c264b4500f5c"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,5))\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(np.arange(0, r_epochs), record_df['mean_overlapping_bboxes'], 'r')\n",
    "plt.title('mean_overlapping_bboxes')\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(np.arange(0, r_epochs), record_df['class_acc'], 'r')\n",
    "plt.title('class_acc')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(15,5))\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(np.arange(0, r_epochs), record_df['loss_rpn_cls'], 'r')\n",
    "plt.title('loss_rpn_cls')\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(np.arange(0, r_epochs), record_df['loss_rpn_regr'], 'r')\n",
    "plt.title('loss_rpn_regr')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "plt.figure(figsize=(15,5))\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(np.arange(0, r_epochs), record_df['loss_class_cls'], 'r')\n",
    "plt.title('loss_class_cls')\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(np.arange(0, r_epochs), record_df['loss_class_regr'], 'r')\n",
    "plt.title('loss_class_regr')\n",
    "plt.show()\n",
    "\n",
    "plt.plot(np.arange(0, r_epochs), record_df['curr_loss'], 'r')\n",
    "plt.title('total_loss')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "frcnn_train_vgg.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
